{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e8efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score,cross_validate,train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc,accuracy_score,precision_recall_curve\n",
    "from sklearn import neighbors,preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "import sklearn.linear_model as LM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.neural_network as net\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import root,fsolve\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest,f_classif,chi2\n",
    "from sklearn.feature_selection import RFE,RFECV,SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LassoCV, lasso_path,Ridge,RidgeCV\n",
    "from sklearn.linear_model import enet_path,ElasticNetCV,ElasticNet\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad6d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Dataset\n",
    "data=pd.read_excel('dataset5.xlsx')\n",
    "X=data.iloc[:,1:86]\n",
    "Y=data.iloc[:,86]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a670bf",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550dc824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Variance Filtering: The number of remaining variables is 29\n",
      "(1628, 29)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Low Variance Filtering\n",
    "selector=VarianceThreshold(threshold=0.05)\n",
    "selector.fit(X)\n",
    "print(\"Low Variance Filtering: The number of remaining variables is %d\"%len(selector.get_support(True)))\n",
    "\n",
    "colIndex = list(selector.get_support(indices=True))\n",
    "X_useFeature1 = X.iloc[:,colIndex]\n",
    "print(X_useFeature1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95cee91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of remaining variables after Lasso regression: 61\n",
      "The best alpha is:  0.0020137797634826008\n",
      "The threshold is: 1e-05\n",
      "Lasso Regression: The number of remaining variables is 24\n",
      "(1628, 24)\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Lasso Regression\n",
    "model = LassoCV()\n",
    "model.fit(X,Y)\n",
    "print('The number of remaining variables after Lasso regression: %d'%sum(model.coef_==0))\n",
    "print('The best alpha is: ',model.alpha_)\n",
    "lassoAlpha=model.alpha_\n",
    "\n",
    "estimator = Lasso(alpha=lassoAlpha) \n",
    "selector=SelectFromModel(estimator=estimator)\n",
    "selector.fit(X,Y)\n",
    "print(\"The threshold is: %s\"%selector.threshold_)\n",
    "print(\"Lasso Regression: The number of remaining variables is %d\"%len(selector.get_support(indices=True)))\n",
    "\n",
    "colIndex = list(selector.get_support(indices=True))\n",
    "X_useFeature2 = X.iloc[:,colIndex]  # get selected features\n",
    "print(X_useFeature2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f6643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of remaining variables after Rridge regression: 10\n",
      "The best alpha is:  10.0\n",
      "The threshold is: 0.0372450007999867\n",
      "Rridge Regression: The number of remaining variables is: 26\n",
      "(1628, 26)\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Rridge Regression\n",
    "modelRidge = RidgeCV()\n",
    "modelRidge.fit(X,Y)\n",
    "print('The number of remaining variables after Rridge regression: %d'%sum(modelRidge.coef_==0))\n",
    "print('The best alpha is: ',modelRidge.alpha_) \n",
    "ridgeAlpha=modelRidge.alpha_\n",
    "\n",
    "estimator = Ridge(alpha=ridgeAlpha) \n",
    "selector=SelectFromModel(estimator=estimator)\n",
    "selector.fit(X,Y)\n",
    "print(\"The threshold is: %s\"%selector.threshold_)\n",
    "print(\"Rridge Regression: The number of remaining variables is: %d\"%len(selector.get_support(indices=True)))\n",
    "\n",
    "colIndex = list(selector.get_support(indices=True))\n",
    "X_useFeature3 = X.iloc[:,colIndex]  # get selected features\n",
    "print(X_useFeature3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c7bdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division of training set and testing set\n",
    "# Without feature selection\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.70, random_state=123) \n",
    "\n",
    "# After Low Variance Filtering\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X_useFeature1,Y,train_size=0.70, random_state=123) \n",
    "\n",
    "# After Lasso Regression\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X_useFeature2,Y,train_size=0.70, random_state=123) \n",
    "\n",
    "# After Ridge Regression\n",
    "X3_train, X3_test, Y3_train, Y3_test = train_test_split(X_useFeature3,Y,train_size=0.70, random_state=123) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4469694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection function\n",
    "def useFeatureSelection(model, X_train, Y_train, X_test, Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_train_pre=model.predict(X_train)\n",
    "    print('Model training result: \\n',classification_report(Y_train,Y_train_pre, digits=4))\n",
    "\n",
    "    Y_test_pre=model.predict(X_test)\n",
    "    print('Model prediction result: \\n',classification_report(Y_test,Y_test_pre, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100618f",
   "metadata": {},
   "source": [
    "# Model 1ï¼šKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4023d007",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d8b9311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5865    0.6186    0.6021       603\n",
      "           1     0.5427    0.5093    0.5255       536\n",
      "\n",
      "    accuracy                         0.5672      1139\n",
      "   macro avg     0.5646    0.5640    0.5638      1139\n",
      "weighted avg     0.5659    0.5672    0.5661      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5526    0.6562    0.6000       256\n",
      "           1     0.5243    0.4163    0.4641       233\n",
      "\n",
      "    accuracy                         0.5419       489\n",
      "   macro avg     0.5385    0.5363    0.5321       489\n",
      "weighted avg     0.5391    0.5419    0.5353       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guassain kernel function\n",
    "def guass(x):\n",
    "    x=preprocessing.scale(x)\n",
    "    output=1/np.sqrt(2*np.pi)*np.exp(-x*x/2)\n",
    "    return output\n",
    "\n",
    "modelKNN=neighbors.KNeighborsClassifier(n_neighbors=10,weights=guass)\n",
    "modelKNN.fit(X_train,Y_train)\n",
    "Y_train_pre=modelKNN.predict(X_train)\n",
    "print('Model training result: \\n',classification_report(Y_train,Y_train_pre, digits=4))\n",
    "\n",
    "Y_test_pre=modelKNN.predict(X_test)\n",
    "print('Model prediction result: \\n',classification_report(Y_test,Y_test_pre, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c501f",
   "metadata": {},
   "source": [
    "## Using Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c47616aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6335    0.6650    0.6489       603\n",
      "           1     0.6008    0.5672    0.5835       536\n",
      "\n",
      "    accuracy                         0.6190      1139\n",
      "   macro avg     0.6171    0.6161    0.6162      1139\n",
      "weighted avg     0.6181    0.6190    0.6181      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5545    0.6562    0.6011       256\n",
      "           1     0.5269    0.4206    0.4678       233\n",
      "\n",
      "    accuracy                         0.5440       489\n",
      "   macro avg     0.5407    0.5384    0.5344       489\n",
      "weighted avg     0.5413    0.5440    0.5376       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "modelKNN1=neighbors.KNeighborsClassifier(n_neighbors=10,weights=guass)\n",
    "useFeatureSelection(modelKNN1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2299ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6210    0.6468    0.6336       603\n",
      "           1     0.5832    0.5560    0.5692       536\n",
      "\n",
      "    accuracy                         0.6040      1139\n",
      "   macro avg     0.6021    0.6014    0.6014      1139\n",
      "weighted avg     0.6032    0.6040    0.6033      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5537    0.6641    0.6039       256\n",
      "           1     0.5275    0.4120    0.4627       233\n",
      "\n",
      "    accuracy                         0.5440       489\n",
      "   macro avg     0.5406    0.5380    0.5333       489\n",
      "weighted avg     0.5412    0.5440    0.5366       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "modelKNN2=neighbors.KNeighborsClassifier(n_neighbors=10,weights=guass)\n",
    "useFeatureSelection(modelKNN2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da985c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8529    0.9420    0.8952       603\n",
      "           1     0.9260    0.8172    0.8682       536\n",
      "\n",
      "    accuracy                         0.8832      1139\n",
      "   macro avg     0.8894    0.8796    0.8817      1139\n",
      "weighted avg     0.8873    0.8832    0.8825      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8063    0.8945    0.8481       256\n",
      "           1     0.8683    0.7639    0.8128       233\n",
      "\n",
      "    accuracy                         0.8323       489\n",
      "   macro avg     0.8373    0.8292    0.8305       489\n",
      "weighted avg     0.8359    0.8323    0.8313       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "modelKNN3=neighbors.KNeighborsClassifier(n_neighbors=10,weights=guass)\n",
    "useFeatureSelection(modelKNN3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e15e53",
   "metadata": {},
   "source": [
    "# Model 2: Naive Bayse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163c49f",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "235e56c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9274    0.2753    0.4246       603\n",
      "           1     0.5448    0.9757    0.6992       536\n",
      "\n",
      "    accuracy                         0.6049      1139\n",
      "   macro avg     0.7361    0.6255    0.5619      1139\n",
      "weighted avg     0.7473    0.6049    0.5538      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8800    0.2578    0.3988       256\n",
      "           1     0.5411    0.9614    0.6924       233\n",
      "\n",
      "    accuracy                         0.5930       489\n",
      "   macro avg     0.7105    0.6096    0.5456       489\n",
      "weighted avg     0.7185    0.5930    0.5387       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelNB = GaussianNB()\n",
    "modelNB.fit(X_train, Y_train)\n",
    "print('Model training result: \\n',classification_report(Y_train,modelNB.predict(X_train), digits=4))\n",
    "print('Model prediction result: \\n',classification_report(Y_test,modelNB.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6914e7c",
   "metadata": {},
   "source": [
    "## Using Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bed36eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7981    0.9768    0.8784       603\n",
      "           1     0.9651    0.7220    0.8260       536\n",
      "\n",
      "    accuracy                         0.8569      1139\n",
      "   macro avg     0.8816    0.8494    0.8522      1139\n",
      "weighted avg     0.8767    0.8569    0.8538      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8058    0.9727    0.8814       256\n",
      "           1     0.9611    0.7425    0.8378       233\n",
      "\n",
      "    accuracy                         0.8630       489\n",
      "   macro avg     0.8835    0.8576    0.8596       489\n",
      "weighted avg     0.8798    0.8630    0.8606       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "modelNB1=GaussianNB()\n",
    "useFeatureSelection(modelNB1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26096ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7891    0.9801    0.8743       603\n",
      "           1     0.9692    0.7052    0.8164       536\n",
      "\n",
      "    accuracy                         0.8507      1139\n",
      "   macro avg     0.8791    0.8427    0.8453      1139\n",
      "weighted avg     0.8738    0.8507    0.8470      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8091    0.9766    0.8850       256\n",
      "           1     0.9667    0.7468    0.8426       233\n",
      "\n",
      "    accuracy                         0.8671       489\n",
      "   macro avg     0.8879    0.8617    0.8638       489\n",
      "weighted avg     0.8842    0.8671    0.8648       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "modelNB2=GaussianNB()\n",
    "useFeatureSelection(modelNB2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6dcbce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9263    0.8342    0.8778       603\n",
      "           1     0.8322    0.9254    0.8763       536\n",
      "\n",
      "    accuracy                         0.8771      1139\n",
      "   macro avg     0.8793    0.8798    0.8771      1139\n",
      "weighted avg     0.8820    0.8771    0.8771      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9159    0.8086    0.8589       256\n",
      "           1     0.8137    0.9185    0.8629       233\n",
      "\n",
      "    accuracy                         0.8609       489\n",
      "   macro avg     0.8648    0.8635    0.8609       489\n",
      "weighted avg     0.8672    0.8609    0.8608       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "modelNB3=GaussianNB()\n",
    "useFeatureSelection(modelNB3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dc888",
   "metadata": {},
   "source": [
    "# Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a479bc",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a16f418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9633    1.0000    0.9813       603\n",
      "           1     1.0000    0.9571    0.9781       536\n",
      "\n",
      "    accuracy                         0.9798      1139\n",
      "   macro avg     0.9816    0.9785    0.9797      1139\n",
      "weighted avg     0.9805    0.9798    0.9798      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9020    0.8984    0.9002       256\n",
      "           1     0.8889    0.8927    0.8908       233\n",
      "\n",
      "    accuracy                         0.8957       489\n",
      "   macro avg     0.8954    0.8956    0.8955       489\n",
      "weighted avg     0.8957    0.8957    0.8957       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelDTC = tree.DecisionTreeClassifier(max_depth=10,random_state=123)\n",
    "modelDTC.fit(X_train, Y_train)\n",
    "print('Model training result: \\n',classification_report(Y_train,modelDTC.predict(X_train), digits=4))\n",
    "print('Model prediction result: \\n',classification_report(Y_test,modelDTC.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede48b35",
   "metadata": {},
   "source": [
    "## Using Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad6a6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9742    1.0000    0.9869       603\n",
      "           1     1.0000    0.9701    0.9848       536\n",
      "\n",
      "    accuracy                         0.9860      1139\n",
      "   macro avg     0.9871    0.9851    0.9859      1139\n",
      "weighted avg     0.9863    0.9860    0.9859      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8880    0.8984    0.8932       256\n",
      "           1     0.8870    0.8755    0.8812       233\n",
      "\n",
      "    accuracy                         0.8875       489\n",
      "   macro avg     0.8875    0.8870    0.8872       489\n",
      "weighted avg     0.8875    0.8875    0.8875       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "modelDTC1 = tree.DecisionTreeClassifier(max_depth=10,random_state=123)\n",
    "useFeatureSelection(modelDTC1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17dd3e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9773    1.0000    0.9885       603\n",
      "           1     1.0000    0.9739    0.9868       536\n",
      "\n",
      "    accuracy                         0.9877      1139\n",
      "   macro avg     0.9887    0.9869    0.9876      1139\n",
      "weighted avg     0.9880    0.9877    0.9877      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8837    0.8906    0.8872       256\n",
      "           1     0.8788    0.8712    0.8750       233\n",
      "\n",
      "    accuracy                         0.8814       489\n",
      "   macro avg     0.8813    0.8809    0.8811       489\n",
      "weighted avg     0.8814    0.8814    0.8814       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso  Regression\n",
    "modelDTC2 = tree.DecisionTreeClassifier(max_depth=10,random_state=123)\n",
    "useFeatureSelection(modelDTC2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1875952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9436    0.9983    0.9702       603\n",
      "           1     0.9980    0.9328    0.9643       536\n",
      "\n",
      "    accuracy                         0.9675      1139\n",
      "   macro avg     0.9708    0.9656    0.9673      1139\n",
      "weighted avg     0.9692    0.9675    0.9674      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8839    0.9219    0.9025       256\n",
      "           1     0.9099    0.8670    0.8879       233\n",
      "\n",
      "    accuracy                         0.8957       489\n",
      "   macro avg     0.8969    0.8944    0.8952       489\n",
      "weighted avg     0.8963    0.8957    0.8955       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rridge Regression\n",
    "modelDTC3 = tree.DecisionTreeClassifier(max_depth=10,random_state=123)\n",
    "useFeatureSelection(modelDTC3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3725d4",
   "metadata": {},
   "source": [
    "# Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1afd4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def useFeatureSelection2(model, X_train, Y_train, X_test, Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_train_pre=model.predict(X_train).round().astype(int)\n",
    "    print('Model training result: \\n',classification_report(np.array(Y_train),Y_train_pre, digits=4))\n",
    "\n",
    "    Y_test_pre=model.predict(X_test).round().astype(int)\n",
    "    print('Model prediction result: \\n',classification_report(np.array(Y_test),Y_test_pre, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43711039",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc7a85d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9067    0.9492    0.9275       256\n",
      "           1     0.9412    0.8927    0.9163       233\n",
      "\n",
      "    accuracy                         0.9223       489\n",
      "   macro avg     0.9239    0.9210    0.9219       489\n",
      "weighted avg     0.9231    0.9223    0.9222       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF=ensemble.RandomForestClassifier(n_estimators=120,oob_score=True,random_state=123,\n",
    "                                      bootstrap=True)\n",
    "RF.fit(X_train,Y_train)    \n",
    "pre_rf_train=RF.predict(X_train).round().astype(int)\n",
    "pre_rf_test=RF.predict(X_test).round().astype(int)\n",
    "print('Model training result: \\n',classification_report(np.array(Y_train),pre_rf_train, digits=4))\n",
    "print('Model prediction result: \\n',classification_report(np.array(Y_test),pre_rf_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591373a",
   "metadata": {},
   "source": [
    "## Using Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9ef4228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9011    0.9609    0.9301       256\n",
      "           1     0.9537    0.8841    0.9176       233\n",
      "\n",
      "    accuracy                         0.9243       489\n",
      "   macro avg     0.9274    0.9225    0.9238       489\n",
      "weighted avg     0.9262    0.9243    0.9241       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "RF1=ensemble.RandomForestClassifier(n_estimators=120,oob_score=True,random_state=123,\n",
    "                                      bootstrap=True)\n",
    "useFeatureSelection2(RF1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dc09dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9124    0.9766    0.9434       256\n",
      "           1     0.9721    0.8970    0.9330       233\n",
      "\n",
      "    accuracy                         0.9387       489\n",
      "   macro avg     0.9423    0.9368    0.9382       489\n",
      "weighted avg     0.9408    0.9387    0.9385       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "RF2=ensemble.RandomForestClassifier(n_estimators=120,\n",
    "                                  oob_score=True,random_state=123,bootstrap=True)\n",
    "useFeatureSelection2(RF2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13138f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9067    0.9492    0.9275       256\n",
      "           1     0.9412    0.8927    0.9163       233\n",
      "\n",
      "    accuracy                         0.9223       489\n",
      "   macro avg     0.9239    0.9210    0.9219       489\n",
      "weighted avg     0.9231    0.9223    0.9222       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "RF3=ensemble.RandomForestClassifier(n_estimators=120,\n",
    "                                  oob_score=True,random_state=123,bootstrap=True)\n",
    "useFeatureSelection2(RF3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502f87e",
   "metadata": {},
   "source": [
    "# Model 5: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda677e",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4f926eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8826    0.9688    0.9236       256\n",
      "           1     0.9615    0.8584    0.9070       233\n",
      "\n",
      "    accuracy                         0.9162       489\n",
      "   macro avg     0.9221    0.9136    0.9153       489\n",
      "weighted avg     0.9202    0.9162    0.9157       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building weak model\n",
    "dt_stump = tree.DecisionTreeClassifier(max_depth=8, min_samples_leaf=1)\n",
    "adaBoost = ensemble.AdaBoostClassifier(estimator=dt_stump,n_estimators=150,\n",
    "                                      random_state=123)\n",
    "adaBoost.fit(X_train,Y_train)\n",
    "\n",
    "pre_adaBoost_train=adaBoost.predict(X_train).round().astype(int)\n",
    "pre_adaBoost_test=adaBoost.predict(X_test).round().astype(int)\n",
    "print('Model training result: \\n',classification_report(np.array(Y_train),pre_adaBoost_train, digits=4))\n",
    "print('Model prediction result: \\n',classification_report(np.array(Y_test),pre_adaBoost_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91922e2a",
   "metadata": {},
   "source": [
    "## Using Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0e44f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8821    0.9648    0.9216       256\n",
      "           1     0.9569    0.8584    0.9050       233\n",
      "\n",
      "    accuracy                         0.9141       489\n",
      "   macro avg     0.9195    0.9116    0.9133       489\n",
      "weighted avg     0.9178    0.9141    0.9137       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "adaBoost1 = ensemble.AdaBoostClassifier(estimator=dt_stump,n_estimators=150,\n",
    "                                      random_state=123)\n",
    "useFeatureSelection2(adaBoost1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92877ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8885    0.9648    0.9251       256\n",
      "           1     0.9573    0.8670    0.9099       233\n",
      "\n",
      "    accuracy                         0.9182       489\n",
      "   macro avg     0.9229    0.9159    0.9175       489\n",
      "weighted avg     0.9213    0.9182    0.9179       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "adaBoost2 = ensemble.AdaBoostClassifier(estimator=dt_stump,n_estimators=150,\n",
    "                                      random_state=123)\n",
    "useFeatureSelection2(adaBoost2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "601b7afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8713    0.9258    0.8977       256\n",
      "           1     0.9124    0.8498    0.8800       233\n",
      "\n",
      "    accuracy                         0.8896       489\n",
      "   macro avg     0.8919    0.8878    0.8889       489\n",
      "weighted avg     0.8909    0.8896    0.8893       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "adaBoost3 = ensemble.AdaBoostClassifier(estimator=dt_stump,n_estimators=150,\n",
    "                                      random_state=123)\n",
    "useFeatureSelection2(adaBoost3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b32fd5",
   "metadata": {},
   "source": [
    "# Model 6: MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901dace7",
   "metadata": {},
   "source": [
    "## Without Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8872fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model traing Result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9215    0.9536    0.9372       603\n",
      "           1     0.9456    0.9086    0.9267       536\n",
      "\n",
      "    accuracy                         0.9324      1139\n",
      "   macro avg     0.9336    0.9311    0.9320      1139\n",
      "weighted avg     0.9328    0.9324    0.9323      1139\n",
      "\n",
      "Model prediction Result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8806    0.9219    0.9008       256\n",
      "           1     0.9095    0.8627    0.8855       233\n",
      "\n",
      "    accuracy                         0.8937       489\n",
      "   macro avg     0.8950    0.8923    0.8931       489\n",
      "weighted avg     0.8944    0.8937    0.8935       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NeuNet=net.MLPClassifier(activation='logistic',random_state=123,hidden_layer_sizes=(60,),max_iter=2000)\n",
    "NeuNet.fit(X_train,Y_train)\n",
    "pre_net_train=NeuNet.predict(X_train)\n",
    "pre_net_test=NeuNet.predict(X_test)\n",
    "print('Model traing Result: \\n',classification_report(Y_train, pre_net_train, digits=4))\n",
    "print('Model prediction Result: \\n',classification_report(Y_test, pre_net_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97cb3e",
   "metadata": {},
   "source": [
    "## Using Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4592288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9221    0.9420    0.9319       603\n",
      "           1     0.9331    0.9104    0.9216       536\n",
      "\n",
      "    accuracy                         0.9271      1139\n",
      "   macro avg     0.9276    0.9262    0.9268      1139\n",
      "weighted avg     0.9273    0.9271    0.9271      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8962    0.9102    0.9031       256\n",
      "           1     0.8996    0.8841    0.8918       233\n",
      "\n",
      "    accuracy                         0.8978       489\n",
      "   macro avg     0.8979    0.8971    0.8974       489\n",
      "weighted avg     0.8978    0.8978    0.8977       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Varaince Filtering\n",
    "NeuNet1=net.MLPClassifier(activation='logistic',random_state=123,hidden_layer_sizes=(60,),max_iter=2000)\n",
    "useFeatureSelection(NeuNet1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ba6101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9141    0.9701    0.9413       603\n",
      "           1     0.9639    0.8974    0.9295       536\n",
      "\n",
      "    accuracy                         0.9359      1139\n",
      "   macro avg     0.9390    0.9338    0.9354      1139\n",
      "weighted avg     0.9375    0.9359    0.9357      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8843    0.9258    0.9046       256\n",
      "           1     0.9140    0.8670    0.8899       233\n",
      "\n",
      "    accuracy                         0.8978       489\n",
      "   macro avg     0.8992    0.8964    0.8972       489\n",
      "weighted avg     0.8985    0.8978    0.8976       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "NeuNet2=net.MLPClassifier(activation='logistic',random_state=123,hidden_layer_sizes=(60,),max_iter=2000)\n",
    "useFeatureSelection(NeuNet2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf09b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9168    0.9320    0.9243       603\n",
      "           1     0.9221    0.9049    0.9134       536\n",
      "\n",
      "    accuracy                         0.9192      1139\n",
      "   macro avg     0.9194    0.9184    0.9189      1139\n",
      "weighted avg     0.9193    0.9192    0.9192      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9144    0.9180    0.9162       256\n",
      "           1     0.9095    0.9056    0.9075       233\n",
      "\n",
      "    accuracy                         0.9121       489\n",
      "   macro avg     0.9119    0.9118    0.9119       489\n",
      "weighted avg     0.9121    0.9121    0.9121       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "NeuNet3=net.MLPClassifier(activation='logistic',random_state=123,hidden_layer_sizes=(60,),max_iter=2000)\n",
    "useFeatureSelection(NeuNet3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654b42e",
   "metadata": {},
   "source": [
    "# Model 7: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee34be",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab8b2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper-parameters:  {'C': 19, 'gamma': 0.0001}\n",
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8320    0.8706    0.8509       603\n",
      "           1     0.8465    0.8022    0.8238       536\n",
      "\n",
      "    accuracy                         0.8385      1139\n",
      "   macro avg     0.8392    0.8364    0.8373      1139\n",
      "weighted avg     0.8388    0.8385    0.8381      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6854    0.7148    0.6998       256\n",
      "           1     0.6712    0.6395    0.6549       233\n",
      "\n",
      "    accuracy                         0.6789       489\n",
      "   macro avg     0.6783    0.6772    0.6774       489\n",
      "weighted avg     0.6786    0.6789    0.6784       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "              'gamma':[0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000]}# pre-setting some parameters\n",
    "\n",
    "\n",
    "modelSVC=svm.SVC(kernel='rbf')\n",
    "clf = GridSearchCV(modelSVC, parameters, cv=5, n_jobs=8)# Grid search with 5-fold cross validation\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "pre_svm_train=clf.predict(X_train)\n",
    "pre_svm_test=clf.predict(X_test)\n",
    "print('The best hyper-parameters: ', clf.best_params_)\n",
    "print('Model training result: \\n',classification_report(Y_train, pre_svm_train, digits=4))\n",
    "print('Model prediction result: \\n',classification_report(Y_test, pre_svm_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd6069",
   "metadata": {},
   "source": [
    "## Using Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "211c16d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8317    0.8690    0.8500       603\n",
      "           1     0.8448    0.8022    0.8230       536\n",
      "\n",
      "    accuracy                         0.8376      1139\n",
      "   macro avg     0.8383    0.8356    0.8365      1139\n",
      "weighted avg     0.8379    0.8376    0.8373      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6854    0.7148    0.6998       256\n",
      "           1     0.6712    0.6395    0.6549       233\n",
      "\n",
      "    accuracy                         0.6789       489\n",
      "   macro avg     0.6783    0.6772    0.6774       489\n",
      "weighted avg     0.6786    0.6789    0.6784       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "clf1 = GridSearchCV(modelSVC, parameters, cv=5, n_jobs=8)# Grid search with 5-fold cross validation\n",
    "useFeatureSelection(clf1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bab83581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8167    0.8574    0.8366       603\n",
      "           1     0.8300    0.7836    0.8061       536\n",
      "\n",
      "    accuracy                         0.8227      1139\n",
      "   macro avg     0.8234    0.8205    0.8214      1139\n",
      "weighted avg     0.8230    0.8227    0.8223      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6766    0.7109    0.6933       256\n",
      "           1     0.6636    0.6266    0.6446       233\n",
      "\n",
      "    accuracy                         0.6708       489\n",
      "   macro avg     0.6701    0.6688    0.6690       489\n",
      "weighted avg     0.6704    0.6708    0.6701       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "clf2 = GridSearchCV(modelSVC, parameters, cv=5, n_jobs=8)# Grid search with 5-fold cross validation\n",
    "useFeatureSelection(clf2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd1e5052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9147    0.9071    0.9109       603\n",
      "           1     0.8965    0.9049    0.9006       536\n",
      "\n",
      "    accuracy                         0.9061      1139\n",
      "   macro avg     0.9056    0.9060    0.9058      1139\n",
      "weighted avg     0.9061    0.9061    0.9061      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9109    0.9180    0.9144       256\n",
      "           1     0.9091    0.9013    0.9052       233\n",
      "\n",
      "    accuracy                         0.9100       489\n",
      "   macro avg     0.9100    0.9096    0.9098       489\n",
      "weighted avg     0.9100    0.9100    0.9100       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "clf3 = GridSearchCV(modelSVC, parameters, cv=5, n_jobs=8)# Grid search with 5-fold cross validation\n",
    "useFeatureSelection(clf3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6da9a1",
   "metadata": {},
   "source": [
    "# Model 8: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27122b2e",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99ec1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9067    0.9492    0.9275       256\n",
      "           1     0.9412    0.8927    0.9163       233\n",
      "\n",
      "    accuracy                         0.9223       489\n",
      "   macro avg     0.9239    0.9210    0.9219       489\n",
      "weighted avg     0.9231    0.9223    0.9222       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGBmodel = XGBClassifier(learning_rate=0.3,\n",
    "                          n_estimators=150,\n",
    "                          max_depth=12)\n",
    "\n",
    "XGBmodel.fit(X_train, Y_train)\n",
    "\n",
    "pre_XGBoost_train=XGBmodel.predict(X_train)\n",
    "pre_XGBoost_test=XGBmodel.predict(X_test)\n",
    "print('Model training result: \\n',classification_report(Y_train,pre_XGBoost_train, digits=4))\n",
    "print('Model prediction result: \\n',classification_report(Y_test,pre_XGBoost_test, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285af13",
   "metadata": {},
   "source": [
    "## Using Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe80ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9064    0.9453    0.9254       256\n",
      "           1     0.9369    0.8927    0.9143       233\n",
      "\n",
      "    accuracy                         0.9202       489\n",
      "   macro avg     0.9217    0.9190    0.9199       489\n",
      "weighted avg     0.9209    0.9202    0.9201       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Low Variance Filtering\n",
    "XGBmodel1 = XGBClassifier(learning_rate=0.3,\n",
    "                          n_estimators=150,\n",
    "                          max_depth=12)\n",
    "useFeatureSelection(XGBmodel1, X1_train, Y1_train, X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd368796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9074    0.9570    0.9316       256\n",
      "           1     0.9498    0.8927    0.9204       233\n",
      "\n",
      "    accuracy                         0.9264       489\n",
      "   macro avg     0.9286    0.9249    0.9260       489\n",
      "weighted avg     0.9276    0.9264    0.9262       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "XGBmodel2 = XGBClassifier(learning_rate=0.3,\n",
    "                          n_estimators=150,\n",
    "                          max_depth=12)\n",
    "useFeatureSelection(XGBmodel2, X2_train, Y2_train, X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84c7f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       603\n",
      "           1     1.0000    1.0000    1.0000       536\n",
      "\n",
      "    accuracy                         1.0000      1139\n",
      "   macro avg     1.0000    1.0000    1.0000      1139\n",
      "weighted avg     1.0000    1.0000    1.0000      1139\n",
      "\n",
      "Model prediction result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8787    0.9336    0.9053       256\n",
      "           1     0.9217    0.8584    0.8889       233\n",
      "\n",
      "    accuracy                         0.8978       489\n",
      "   macro avg     0.9002    0.8960    0.8971       489\n",
      "weighted avg     0.8992    0.8978    0.8975       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "XGBmodel3 = XGBClassifier(learning_rate=0.3,\n",
    "                          n_estimators=150,\n",
    "                          max_depth=12)\n",
    "useFeatureSelection(XGBmodel3, X3_train, Y3_train, X3_test, Y3_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
